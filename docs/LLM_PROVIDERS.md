# LLM Providers Guide

## à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸ LLM à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š

Witmind à¸£à¸­à¸‡à¸£à¸±à¸š 3 providers:

### 1. ðŸŒŸ OpenRouter (à¹à¸™à¸°à¸™à¸³!)

**à¸—à¸³à¹„à¸¡à¸–à¸¶à¸‡à¹à¸™à¸°à¸™à¸³:**
- âœ… à¸„à¸µà¸¢à¹Œà¹€à¸”à¸µà¸¢à¸§ à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸«à¸¥à¸²à¸¢ models (Claude, GPT-4, Gemini, Llama)
- âœ… à¸¡à¸µ **models à¸Ÿà¸£à¸µ** à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸”à¸ªà¸­à¸š
- âœ… Pay-as-you-go (à¹„à¸¡à¹ˆà¸¡à¸µ subscription)
- âœ… à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¸à¸§à¹ˆà¸² API à¸•à¸£à¸‡

**Setup:**
```bash
# 1. à¸ªà¸¡à¸±à¸„à¸£à¸—à¸µà¹ˆ https://openrouter.ai
# 2. à¹„à¸›à¸—à¸µà¹ˆ https://openrouter.ai/keys
# 3. à¸ªà¸£à¹‰à¸²à¸‡ API key
# 4. à¹€à¸žà¸´à¹ˆà¸¡à¹ƒà¸™ .env

echo "OPENROUTER_API_KEY=sk-or-v1-xxx" >> ~/.env
```

**Models à¹à¸™à¸°à¸™à¸³:**

| Model | à¸£à¸²à¸„à¸² | à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸š |
|-------|------|------------|
| `google/gemini-flash-1.5` | **à¸Ÿà¸£à¸µ!** | Development, Testing |
| `meta-llama/llama-3.2-3b-instruct` | **à¸Ÿà¸£à¸µ!** | Simple tasks |
| `anthropic/claude-3-haiku` | à¸–à¸¹à¸ (~$0.25/1M) | Fast tasks |
| `anthropic/claude-3.5-sonnet` | à¸›à¸²à¸™à¸à¸¥à¸²à¸‡ (~$3/1M) | Smart agents |
| `openai/gpt-4o` | à¹à¸žà¸‡ (~$2.50/1M) | Complex tasks |

**à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**

```python
# à¹ƒà¸Šà¹‰ model à¸Ÿà¸£à¸µ (Gemini)
llm = create_llm_client(
    provider='openrouter',
    model='google/gemini-flash-1.5'
)

# à¹ƒà¸Šà¹‰ Claude à¸œà¹ˆà¸²à¸™ OpenRouter
llm = create_llm_client(
    provider='openrouter',
    model='anthropic/claude-3.5-sonnet'
)

# à¹ƒà¸Šà¹‰ GPT-4
llm = create_llm_client(
    provider='openrouter',
    model='openai/gpt-4o'
)
```

---

### 2. ðŸ¤– Claude (Anthropic API)

**à¸‚à¹‰à¸­à¸”à¸µ:**
- âœ… à¸‰à¸¥à¸²à¸”à¸—à¸µà¹ˆà¸ªà¸¸à¸” à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™
- âœ… API à¸•à¸£à¸‡à¸ˆà¸²à¸ Anthropic
- âœ… Sonnet 4.5 à¸£à¸¸à¹ˆà¸™à¸¥à¹ˆà¸²à¸ªà¸¸à¸”

**à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢:**
- âŒ à¹à¸¢à¸à¸ˆà¸²à¸ claude.ai subscription
- âŒ à¸•à¹‰à¸­à¸‡à¹€à¸•à¸´à¸¡à¹€à¸‡à¸´à¸™à¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³ $5
- âŒ à¹à¸žà¸‡à¸à¸§à¹ˆà¸² OpenRouter à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢

**Setup:**
```bash
# 1. à¹„à¸› https://console.anthropic.com
# 2. à¸ªà¸¡à¸±à¸„à¸£ à¹à¸¥à¸°à¹€à¸•à¸´à¸¡à¹€à¸‡à¸´à¸™
# 3. à¸ªà¸£à¹‰à¸²à¸‡ API key
# 4. à¹€à¸žà¸´à¹ˆà¸¡à¹ƒà¸™ .env

echo "ANTHROPIC_API_KEY=sk-ant-xxx" >> ~/.env
```

**à¸£à¸²à¸„à¸²:**
- Sonnet 4.5: ~$3/1M input tokens
- Haiku 4: ~$0.25/1M input tokens

**à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**
```python
llm = create_llm_client(provider='claude')

# à¸ˆà¸°à¹ƒà¸Šà¹‰ claude-sonnet-4-20250514 (à¸¥à¹ˆà¸²à¸ªà¸¸à¸”)
```

---

### 3. ðŸ–¥ï¸ Ollama (Local, à¸Ÿà¸£à¸µ)

**à¸‚à¹‰à¸­à¸”à¸µ:**
- âœ… **à¸Ÿà¸£à¸µ 100%** à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢
- âœ… à¸£à¸±à¸™à¸šà¸™ server à¸™à¸µà¹‰à¹€à¸­à¸‡
- âœ… à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ API key
- âœ… Privacy (data à¹„à¸¡à¹ˆà¸­à¸­à¸à¸ˆà¸²à¸ server)

**à¸‚à¹‰à¸­à¹€à¸ªà¸µà¸¢:**
- âŒ à¹„à¸¡à¹ˆà¸‰à¸¥à¸²à¸”à¹€à¸—à¹ˆà¸² Claude/GPT-4
- âŒ à¸Šà¹‰à¸²à¸à¸§à¹ˆà¸² (à¸–à¹‰à¸² CPU/GPU à¸­à¹ˆà¸­à¸™)
- âŒ à¹ƒà¸Šà¹‰ RAM/VRAM à¹€à¸¢à¸­à¸°

**Setup:**
```bash
# Ollama à¸£à¸±à¸™à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§à¹ƒà¸™ Docker
docker compose ps ollama  # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š

# à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸£à¸±à¸™
cd ~/witmind/docker
docker compose up -d ollama
```

**Models à¸—à¸µà¹ˆà¸¡à¸µ:**
```bash
# à¸”à¸¹ models à¸—à¸µà¹ˆà¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹à¸¥à¹‰à¸§
docker exec ollama ollama list

# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ model à¹ƒà¸«à¸¡à¹ˆ
docker exec ollama ollama pull llama3.2
docker exec ollama ollama pull codellama
docker exec ollama ollama pull mistral
```

**à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**
```python
# à¹ƒà¸Šà¹‰ Ollama à¹ƒà¸™ Docker
llm = create_llm_client(
    provider='ollama',
    base_url='http://ollama:11434',  # Docker service
    model='llama3.2'
)

# à¸–à¹‰à¸²à¸£à¸±à¸™ Ollama à¸™à¸­à¸ Docker
llm = create_llm_client(
    provider='ollama',
    base_url='http://localhost:11434',
    model='llama3.2'
)
```

---

## à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š

| Feature | OpenRouter | Claude | Ollama |
|---------|-----------|--------|--------|
| **à¸£à¸²à¸„à¸²** | à¸Ÿà¸£à¸µ-à¸›à¸²à¸™à¸à¸¥à¸²à¸‡ | à¸›à¸²à¸™à¸à¸¥à¸²à¸‡ | **à¸Ÿà¸£à¸µ** |
| **à¸„à¸§à¸²à¸¡à¸‰à¸¥à¸²à¸”** | à¸”à¸µà¸¡à¸²à¸ | **à¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”** | à¸žà¸­à¹ƒà¸Šà¹‰ |
| **à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§** | à¹€à¸£à¹‡à¸§ | à¹€à¸£à¹‡à¸§ | à¸Šà¹‰à¸² |
| **Setup** | à¸‡à¹ˆà¸²à¸¢ | à¸‡à¹ˆà¸²à¸¢ | **à¸‡à¹ˆà¸²à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”** |
| **Privacy** | à¸ªà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸­à¸ | à¸ªà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸­à¸ | **à¹„à¸¡à¹ˆà¸ªà¹ˆà¸‡à¸­à¸­à¸** |
| **Models** | **à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§** | Claude only | à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§ |

---

## à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸° Use Case

### ðŸ§ª Development & Testing
```python
# à¹ƒà¸Šà¹‰ OpenRouter + Gemini (à¸Ÿà¸£à¸µ!)
llm = create_llm_client('openrouter', model='google/gemini-flash-1.5')
```

### ðŸŽ¯ Production (Smart Agents)
```python
# à¹ƒà¸Šà¹‰ OpenRouter + Claude (à¸–à¸¹à¸à¸à¸§à¹ˆà¸² API à¸•à¸£à¸‡)
llm = create_llm_client('openrouter', model='anthropic/claude-3.5-sonnet')
```

### ðŸ”’ Privacy-focused / No internet
```python
# à¹ƒà¸Šà¹‰ Ollama (local)
llm = create_llm_client('ollama', base_url='http://ollama:11434')
```

### ðŸ’° Free forever
```python
# à¹ƒà¸Šà¹‰ Ollama
llm = create_llm_client('ollama', model='llama3.2', base_url='http://ollama:11434')
```

---

## à¸—à¸”à¸ªà¸­à¸šà¸§à¹ˆà¸² Provider à¹„à¸«à¸™à¹ƒà¸Šà¹‰à¹„à¸”à¹‰

```bash
cd ~/witmind

# à¸—à¸”à¸ªà¸­à¸šà¸—à¸¸à¸ providers
python3 examples/test_llm_providers.py

# à¸ˆà¸°à¹à¸ªà¸”à¸‡:
# âœ… Working providers
# âŒ Failed providers
# ðŸ’¡ Recommendations
```

---

## Configuration à¹à¸™à¸°à¸™à¸³

### à¸ªà¸³à¸«à¸£à¸±à¸š Development:

```bash
# ~/.env
OPENROUTER_API_KEY=sk-or-v1-xxx  # à¸ªà¸¡à¸±à¸„à¸£à¸Ÿà¸£à¸µà¸—à¸µà¹ˆ openrouter.ai
```

```python
# à¹ƒà¸Šà¹‰ model à¸Ÿà¸£à¸µ
llm = create_llm_client('openrouter', model='google/gemini-flash-1.5')
```

### à¸ªà¸³à¸«à¸£à¸±à¸š Production:

```bash
# ~/.env
OPENROUTER_API_KEY=sk-or-v1-xxx
```

```python
# Agent config
pm_agent = create_intelligent_agent(
    agent_id='pm',
    llm_client=create_llm_client('openrouter', model='anthropic/claude-3.5-sonnet'),
    ...
)

frontend_dev = create_intelligent_agent(
    agent_id='frontend_dev',
    llm_client=create_llm_client('openrouter', model='anthropic/claude-3-haiku'),  # à¸–à¸¹à¸à¸à¸§à¹ˆà¸²
    ...
)

qa_tester = create_intelligent_agent(
    agent_id='qa',
    llm_client=create_llm_client('ollama', model='llama3.2'),  # à¸Ÿà¸£à¸µ
    ...
)
```

---

## Quick Start

1. **à¸ªà¸¡à¸±à¸„à¸£ OpenRouter** (à¹à¸™à¸°à¸™à¸³!):
   - à¹„à¸› https://openrouter.ai/keys
   - à¸ªà¸£à¹‰à¸²à¸‡ API key
   - `echo "OPENROUTER_API_KEY=xxx" >> ~/.env`

2. **à¸—à¸”à¸ªà¸­à¸š**:
   ```bash
   cd ~/witmind
   export $(grep -v '^#' ~/.env | xargs)
   python3 examples/test_llm_providers.py
   ```

3. **à¹ƒà¸Šà¹‰à¸‡à¸²à¸™**:
   ```python
   from core.llm_client import create_llm_client

   llm = create_llm_client('openrouter', model='google/gemini-flash-1.5')
   response = llm.chat(messages=[{'role': 'user', 'content': 'Hello!'}])
   ```

---

## Resources

- **OpenRouter**: https://openrouter.ai
- **Claude API**: https://console.anthropic.com
- **Ollama**: https://ollama.ai
- **Model Rankings**: https://openrouter.ai/rankings
