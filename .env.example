# ===========================================
# Witmind Platform Configuration
# ===========================================
# Copy this file to ~/.env and fill in your values
# NEVER commit .env file with real values!
# ===========================================

# --- LLM API Keys ---
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxx

# Get from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-xxxxxxxxxxxxxxxxxxxxx

# Get from: https://platform.openai.com/api-keys (optional)
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxx

# --- DigitalOcean ---
# Get from: https://cloud.digitalocean.com/account/api/tokens
DO_API_TOKEN=dop_v1_xxxxxxxxxxxxxxxxxxxxx

# --- Database ---
MONGODB_URI=mongodb://localhost:27017/witmind
REDIS_URL=redis://localhost:6379

# --- Paths ---
# Root directory for platform runtime data (projects, logs, cache)
# Default: ~/witmind-data
# WITMIND_ROOT=/path/to/witmind-data

# --- Server Connection ---
# For remote CLI access (optional)
SERVER_HOST=192.168.x.x
SERVER_USER=wit
# SERVER_SSH_KEY=~/.ssh/id_ed25519

# --- Mission Control ---
# Basic auth for web dashboard
MC_BASIC_AUTH_USER=admin
MC_BASIC_AUTH_PASS=your-secure-password-here

# --- Code Server ---
# VS Code in browser password
CODE_SERVER_PASSWORD=your-secure-password-here

# --- DDNS ---
# Auto-update DNS for dynamic IP
DDNS_DOMAIN=example.com
DDNS_SUBDOMAIN=home

# --- LLM Presets ---
# max_quality: Claude Opus for all agents
# balanced: Mix of Opus/Sonnet
# cost_saving: Sonnet/Haiku
# local_only: Ollama (free)
DEFAULT_LLM_PRESET=balanced

# --- Ollama (Local LLM) ---
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2
